llm:
  openai:
    provider: "openai"
    model_name: "o4-mini"
    temperature: 0.7

  groq:
    provider: "groq"
    model_name: "deepseek-r1-distill-llama-70b"
  
  